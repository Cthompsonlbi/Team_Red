{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31265f96",
   "metadata": {},
   "source": [
    "# Warning Run Time\n",
    "### File has a run time of ~ 5 hours!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "548f1669",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9fc8799",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\CTHOMP~1\\AppData\\Local\\Temp/ipykernel_20936/3097853145.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mConfusionMatrixDisplay\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbalanced_accuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "# import dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from config import db_password\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# stopwatch\n",
    "import time\n",
    "\n",
    "# ML\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier, EasyEnsembleClassifier\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17830ba",
   "metadata": {},
   "source": [
    "## Connection to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c26833b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create connection string to postgres DB\n",
    "db_string =f'postgresql://postgres:{db_password}@127.0.0.1:5432/Project Insights on the Beach'\n",
    "engine = create_engine(db_string)\n",
    "\n",
    "# read in the clean data from PGAdmin - SQL \n",
    "vacay_df = pd.read_sql_query('''SELECT*FROM cleaned_up_cust_marketing_table;''',engine)\n",
    "\n",
    "# If not connected\n",
    "#vacay_df = pd.read_csv(\"../cleaned_up_cust_marketing_table.csv\")\n",
    "\n",
    "#vacay_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ad79f6",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4526a0d6",
   "metadata": {},
   "source": [
    "#### Remove target and unrelated columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253fef9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns not needed\n",
    "features_df = vacay_df.copy()\n",
    "features_df = features_df.drop([\"prodtaken\",\"customerid\",\"designation\",\"numberofpersonvisiting\",\"numberofchildrenvisiting\"], axis=1)\n",
    "features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b641aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate our categorical variable list\n",
    "features_df_cat = features_df.dtypes[features_df.dtypes == \"object\"].index.tolist()\n",
    "\n",
    "# Check the number of unique values in each column\n",
    "features_df[features_df_cat].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a9d3ad",
   "metadata": {},
   "source": [
    "#### OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd307d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a OneHotEncoder instance\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Fit and transform the OneHotEncoder using the categorical variable list\n",
    "encode_df = pd.DataFrame(enc.fit_transform(features_df[features_df_cat]))\n",
    "\n",
    "# Add the encoded variable names to the dataframe\n",
    "encode_df.columns = enc.get_feature_names(features_df_cat)\n",
    "encode_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94db1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge one-hot encoded features to features_df\n",
    "features_df = features_df.merge(encode_df,left_index=True, right_index=True)\n",
    "\n",
    "# Remove original unencoded columns\n",
    "features_df = features_df.drop(features_df_cat,1)\n",
    "features_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e7ccac",
   "metadata": {},
   "source": [
    "#### Scaling X, splitting test groups, and resampling with Naive Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0118b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the features set.\n",
    "X = features_df.copy()\n",
    "\n",
    "# Define the target set.\n",
    "y = vacay_df[\"prodtaken\"]\n",
    "\n",
    "# Check the balance of our target values\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49066fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data with StandardScaler()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the data\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# View first row\n",
    "X_scaled[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456bc823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, random_state=78)\n",
    "\n",
    "# Resample the training data with the RandomOversampler\n",
    "ros = RandomOverSampler(random_state=1)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f85a555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the train vs test allocation\n",
    "print(Counter(y_train))\n",
    "print(Counter(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0efa70d",
   "metadata": {},
   "source": [
    "## Random Forest Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b92c50c",
   "metadata": {},
   "source": [
    "### Without Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66dc88cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Stratified K-Fold Cross Validation (5 & 10-Fold)\n",
    "n_folds = [5,10]\n",
    "\n",
    "estimators = [100, 250, 500, 750, 1000]\n",
    "accuracy_scores = []\n",
    "\n",
    "for fold in n_folds:\n",
    "    skf = StratifiedKFold(n_splits=fold)\n",
    "    for e in estimators:\n",
    "\n",
    "        # Instantiate random forest classifier and set results to 0 for each iteration\n",
    "        brclf = BalancedRandomForestClassifier(random_state=1, n_estimators=e)\n",
    "        results = 0\n",
    "\n",
    "        # split the data in train and validation sets\n",
    "        for train_index, test_index in skf.split(X_scaled, y):\n",
    "            X_t = X_scaled[train_index]\n",
    "            X_val = X_scaled[test_index]\n",
    "            y_t = y[train_index]\n",
    "            y_val = y[test_index]\n",
    "\n",
    "            # fit\n",
    "            brclf=brclf.fit(X_t, y_t)\n",
    "\n",
    "            # predict\n",
    "            y_pred_k = brclf.predict(X_val)\n",
    "\n",
    "            # extract accuracy score\n",
    "            results += balanced_accuracy_score(y_val, y_pred_k)\n",
    "\n",
    "        # add mean of total result to accuracy score list\n",
    "        accuracy_scores.append(results/fold)\n",
    "\n",
    "        # Print results\n",
    "        print(f'Acc Score with {fold} folds and {e} estimators: {accuracy_scores[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46bf08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model with optimal estimators\n",
    "brclf = BalancedRandomForestClassifier(n_estimators=500, random_state=1)\n",
    "\n",
    "# fit\n",
    "brclf.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "y_pred_brf = brclf.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "brf_acc_score = balanced_accuracy_score(y_test, y_pred_brf)\n",
    "print(balanced_accuracy_score(y_test, y_pred_brf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9a564b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred_brf)\n",
    "\n",
    "#Display confusion matrix using ConfusinMatrixDisplay\n",
    "display_brf = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=brclf.classes_)\n",
    "display_brf.plot()\n",
    "\n",
    "#Save Image\n",
    "#plt.savefig(\"../Images/brf_cm.png\")\n",
    "plt.show()\n",
    "\n",
    "class_brf = classification_report(y_test, y_pred_brf)\n",
    "# Create balanced classification report for Random Forest\n",
    "print(\"Random Forest Classification Report Without Resampling\")\n",
    "print(classification_report(y_test, y_pred_brf))\n",
    "print(\"-----------------------------------\")\n",
    "print(f'Accuracy Score: {brf_acc_score}')\n",
    "print(\"-----------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77e61bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the features sorted in descending order by feature importance\n",
    "by_features = sorted(zip(brclf.feature_importances_, X.columns), reverse=True)\n",
    "for feature_rank in by_features:\n",
    "    print(f\"{feature_rank[1]}: ({feature_rank[0]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3176ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chart important features in optimized Random Forest\n",
    "feat_importances = pd.Series(brclf.feature_importances_, index=X.columns)\n",
    "feat_importances.nlargest(20).plot(kind='barh',color=['blue', 'red', 'green', 'yellow', 'cyan']).invert_yaxis()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e83026a",
   "metadata": {},
   "source": [
    "### With Naive Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ea702a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Stratified K-Fold Cross Validation (5 & 10-Fold)\n",
    "n_folds = [5,10]\n",
    "\n",
    "estimators = [100, 250, 500, 750, 1000]\n",
    "accuracy_scores = []\n",
    "\n",
    "for fold in n_folds:\n",
    "    skf = StratifiedKFold(n_splits=fold)\n",
    "    for e in estimators:\n",
    "\n",
    "        # Instantiate random forest classifier and set results to 0 for each iteration\n",
    "        brclf = BalancedRandomForestClassifier(random_state=1, n_estimators=e)\n",
    "        results = 0\n",
    "\n",
    "        # split the data in train and validation sets\n",
    "        for train_index, test_index in skf.split(X_resampled, y_resampled):\n",
    "            X_t = X_resampled[train_index]\n",
    "            X_val = X_resampled[test_index]\n",
    "            y_t = y_resampled[train_index]\n",
    "            y_val = y_resampled[test_index]\n",
    "\n",
    "            # fit\n",
    "            brclf=brclf.fit(X_t, y_t)\n",
    "\n",
    "            # predict\n",
    "            y_pred_k = brclf.predict(X_val)\n",
    "\n",
    "            # extract accuracy score\n",
    "            results += balanced_accuracy_score(y_val, y_pred_k)\n",
    "\n",
    "        # add mean of total result to accuracy score list\n",
    "        accuracy_scores.append(results/fold)\n",
    "\n",
    "        # Print results\n",
    "        print(f'Acc Score with {fold} folds and {e} estimators: {accuracy_scores[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8130bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model with optimal estimators\n",
    "brclf = BalancedRandomForestClassifier(n_estimators=750, random_state=1)\n",
    "\n",
    "# fit with resampled data\n",
    "brclf.fit(X_resampled, y_resampled)\n",
    "\n",
    "# predict\n",
    "y_pred_brfr = brclf.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "brfr_acc_score = balanced_accuracy_score(y_test, y_pred_brfr)\n",
    "print(balanced_accuracy_score(y_test, y_pred_brfr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0ee26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred_brfr)\n",
    "\n",
    "#Display confusion matrix using ConfusinMatrixDisplay\n",
    "display_brfr = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=brclf.classes_)\n",
    "display_brfr.plot()\n",
    "\n",
    "#Save Image\n",
    "#plt.savefig(\"../Images/brf_cm.png\")\n",
    "plt.show()\n",
    "\n",
    "class_brfr = classification_report(y_test, y_pred_brfr)\n",
    "# Create balanced classification report for Random Forest\n",
    "print(\"Random Forest Classification Report With Oversampling\")\n",
    "print(classification_report(y_test, y_pred_brfr))\n",
    "print(\"-----------------------------------\")\n",
    "print(f'Accuracy Score: {brfr_acc_score}')\n",
    "print(\"-----------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8efafbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the features sorted in descending order by feature importance\n",
    "by_features = sorted(zip(brclf.feature_importances_, X.columns), reverse=True)\n",
    "for feature_rank in by_features:\n",
    "    print(f\"{feature_rank[1]}: ({feature_rank[0]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06afeac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chart important features in optimized, resampled Random Forest\n",
    "feat_importances = pd.Series(brclf.feature_importances_, index=X.columns)\n",
    "feat_importances.nlargest(20).plot(kind='barh',color=['blue', 'red', 'green', 'yellow', 'cyan']).invert_yaxis()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f731cbeb",
   "metadata": {},
   "source": [
    "## Extreme Gradient Boosting (XGBoost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d474d4ad",
   "metadata": {},
   "source": [
    "### Without Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ea263e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Stratified K-Fold --- current settings iterate 1,296 (2,592 with 5/10 fold) times :)\n",
    "\n",
    "# start timer\n",
    "start_time = time.process_time()\n",
    "\n",
    "# Define parameters and set accuracy score list to blank\n",
    "n_folds = [5,10]\n",
    "estimators = [50, 150, 250, 350, 450, 550]\n",
    "depths = [5, 6, 7, 8, 9, 10]\n",
    "col_samples = [0.5, 0.55, 0.6, 0.65]\n",
    "gammas = [0.2, 0.4, 0.6]\n",
    "learn_rates = [0.2, 0.25, 0.3]\n",
    "\n",
    "# Create dictionary to hold model with highest accuracy and the relative parameters\n",
    "max_value_params = {\"acc\":0, \"folds\":0, \"estimators\":0, \"depths\":0, \"colsample_bytree\":0, \"gamma\":0, \"learn\":0}\n",
    "accuracy_scores = []\n",
    "iterations = 0\n",
    "\n",
    "# Iterate through K-fold CV\n",
    "for fold in n_folds:\n",
    "    skf = StratifiedKFold(n_splits=fold)\n",
    "\n",
    "    # Nested for loops to fine-tune parameters\n",
    "    for e in estimators:\n",
    "\n",
    "        for d in depths:\n",
    "\n",
    "            for c in col_samples:\n",
    "\n",
    "                for g in gammas:\n",
    "\n",
    "                    for l in learn_rates:\n",
    "\n",
    "                        # set results = 0 for each iteration\n",
    "                        results = 0\n",
    "\n",
    "                        # Instantiate XGB Classifier model and set results to 0 for each iteration\n",
    "                        xg_clf = xgb.XGBClassifier(objective='binary:logistic', use_label_encoder=False,\n",
    "                                                       eval_metric='mlogloss', learning_rate=l,\n",
    "                                                       n_estimators=e, gamma=g, colsample_bytree=c,\n",
    "                                                       max_depth=d, random_state=1)\n",
    "\n",
    "                        # Split the data into train and validation sets\n",
    "                        for train_index, test_index in skf.split(X_scaled, y):\n",
    "                            X_t = X_scaled[train_index]\n",
    "                            X_val = X_scaled[test_index]\n",
    "                            y_t = y[train_index]\n",
    "                            y_val = y[test_index]\n",
    "\n",
    "                            # Fit the model\n",
    "                            xg_clf = xg_clf.fit(X_t, y_t)\n",
    "\n",
    "                            # Predict\n",
    "                            y_pred_xg = xg_clf.predict(X_val)\n",
    "\n",
    "                            # Extract results\n",
    "                            results += balanced_accuracy_score(y_val, y_pred_xg)\n",
    "\n",
    "                        # add mean of total result to accuracy score list\n",
    "                        accuracy_scores.append(results/fold)\n",
    "\n",
    "                        # Update max_value_params dict if new max accuracy score appears\n",
    "                        if max_value_params['acc'] < max(accuracy_scores):\n",
    "                            max_value_params['acc'] = max(accuracy_scores)\n",
    "                            max_value_params['folds'] = fold\n",
    "                            max_value_params['estimators'] = e\n",
    "                            max_value_params['depths'] = d\n",
    "                            max_value_params['colsample_bytree'] = c\n",
    "                            max_value_params['gamma'] = g\n",
    "                            max_value_params['learn'] = l\n",
    "\n",
    "                        # Print results and iteration number to see progress\n",
    "                        iterations = iterations + 1\n",
    "\n",
    "                        if iterations % 50 == 0:\n",
    "                            print(f'iteration {iterations}')\n",
    "\n",
    "                        print(f'{fold} folds, {e} estimators, {d} depths, colsample_bytree={c}, gamma={g}, learn={l}: \\\n",
    "                        {accuracy_scores[-1] * 100:.3f}% accuracy')\n",
    "\n",
    "\n",
    "# stop timer and print execution duraion\n",
    "end_time = time.process_time()\n",
    "print(f\"Elapsed time = {(end_time - start_time)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8504f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model results\n",
    "print(f'Best model performance and corresponding parameters: \\n {max_value_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c529a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use best XGBoost parameters to predict \n",
    "# Create model and set parameters\n",
    "xg_clf = xgb.XGBClassifier(objective='binary:logistic', use_label_encoder=False,\n",
    "                            eval_metric='mlogloss',\n",
    "                            n_estimators = max_value_params['estimators'],\n",
    "                            max_depth = max_value_params['depths'],\n",
    "                            colsample_bytree = max_value_params['colsample_bytree'],\n",
    "                            gamma = max_value_params['gamma'],\n",
    "                            learning_rate = max_value_params['learn'], random_state=1)\n",
    "\n",
    "# Fit the model\n",
    "xg_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_xg = xg_clf.predict(X_test)\n",
    "\n",
    "# Extract accuracy\n",
    "xg_acc_score = balanced_accuracy_score(y_test, y_pred_xg)\n",
    "balanced_accuracy_score(y_pred_xg, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51edb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create confusion matrix for XGBoost\n",
    "cm = confusion_matrix(y_test, y_pred_xg)\n",
    "\n",
    "#Display confusion matrix using ConfusinMatrixDisplay\n",
    "display_xgb = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=xg_clf.classes_)\n",
    "display_xgb.plot()\n",
    "\n",
    "class_xg = classification_report(y_test, y_pred_xg)\n",
    "# Create balanced classification report for XGBoost\n",
    "print(\"XGBoost Classification Report Without Resampling\")\n",
    "print(classification_report(y_test, y_pred_xg))\n",
    "print(\"-----------------------------------\")\n",
    "print(f'Accuracy Score: {xg_acc_score}')\n",
    "print(\"-----------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355334f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the XGBoost important features\n",
    "xgb.plot_importance(xg_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a168b3",
   "metadata": {},
   "source": [
    "### With Naive Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feed634e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Stratified K-Fold --- current settings iterate 1,296 (2,592 with 5/10 fold) times :)\n",
    "\n",
    "# start timer\n",
    "start_time = time.process_time()\n",
    "\n",
    "# Define parameters and set accuracy score list to blank\n",
    "n_folds = [5,10]\n",
    "estimators = [50, 150, 250, 350, 450, 550]\n",
    "depths = [5, 6, 7, 8, 9, 10]\n",
    "col_samples = [0.5, 0.55, 0.6, 0.65]\n",
    "gammas = [0.2, 0.4, 0.6]\n",
    "learn_rates = [0.2, 0.25, 0.3]\n",
    "\n",
    "# Create dictionary to hold model with highest accuracy and the relative parameters\n",
    "max_value_params = {\"acc\":0, \"folds\":0, \"estimators\":0, \"depths\":0, \"colsample_bytree\":0, \"gamma\":0, \"learn\":0}\n",
    "accuracy_scores = []\n",
    "iterations = 0\n",
    "\n",
    "# Iterate through K-fold CV\n",
    "for fold in n_folds:\n",
    "    skf = StratifiedKFold(n_splits=fold)\n",
    "\n",
    "    # Nested for loops to fine-tune parameters\n",
    "    for e in estimators:\n",
    "\n",
    "        for d in depths:\n",
    "\n",
    "            for c in col_samples:\n",
    "\n",
    "                for g in gammas:\n",
    "\n",
    "                    for l in learn_rates:\n",
    "\n",
    "                        # set results = 0 for each iteration\n",
    "                        results = 0\n",
    "\n",
    "                        # Instantiate XGB Classifier model and set results to 0 for each iteration\n",
    "                        xg_clf = xgb.XGBClassifier(objective='binary:logistic', use_label_encoder=False,\n",
    "                                                       eval_metric='mlogloss', learning_rate=l,\n",
    "                                                       n_estimators=e, gamma=g, colsample_bytree=c,\n",
    "                                                       max_depth=d, random_state=1)\n",
    "\n",
    "                        # Split the data into train and validation sets\n",
    "                        for train_index, test_index in skf.split(X_resampled, y_resampled):\n",
    "                            X_t = X_resampled[train_index]\n",
    "                            X_val = X_resampled[test_index]\n",
    "                            y_t = y_resampled[train_index]\n",
    "                            y_val = y_resampled[test_index]\n",
    "\n",
    "                            # Fit the model\n",
    "                            xg_clf = xg_clf.fit(X_t, y_t)\n",
    "\n",
    "                            # Predict\n",
    "                            y_pred_xgr = xg_clf.predict(X_val)\n",
    "\n",
    "                            # Extract results\n",
    "                            results += balanced_accuracy_score(y_val, y_pred_xgr)\n",
    "\n",
    "                        # add mean of total result to accuracy score list\n",
    "                        accuracy_scores.append(results/fold)\n",
    "\n",
    "                        # Update max_value_params dict if new max accuracy score appears\n",
    "                        if max_value_params['acc'] < max(accuracy_scores):\n",
    "                            max_value_params['acc'] = max(accuracy_scores)\n",
    "                            max_value_params['folds'] = fold\n",
    "                            max_value_params['estimators'] = e\n",
    "                            max_value_params['depths'] = d\n",
    "                            max_value_params['colsample_bytree'] = c\n",
    "                            max_value_params['gamma'] = g\n",
    "                            max_value_params['learn'] = l\n",
    "\n",
    "                        # Print results and iteration number to see progress\n",
    "                        iterations = iterations + 1\n",
    "\n",
    "                        if iterations % 50 == 0:\n",
    "                            print(f'iteration {iterations}')\n",
    "\n",
    "                        print(f'{fold} folds, {e} estimators, {d} depths, colsample_bytree={c}, gamma={g}, learn={l}: \\\n",
    "                        {accuracy_scores[-1] * 100:.3f}% accuracy')\n",
    "\n",
    "\n",
    "# stop timer and print execution duraion\n",
    "end_time = time.process_time()\n",
    "print(f\"Elapsed time = {(end_time - start_time)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792f663c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirmation of best model\n",
    "print(f'Best model performance and corresponding parameters: \\n {max_value_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9aaaa55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use best XGBoost parameters to predict \n",
    "# Create model and set parameters\n",
    "xg_clf = xgb.XGBClassifier(objective='binary:logistic', use_label_encoder=False,\n",
    "                            eval_metric='mlogloss',\n",
    "                            n_estimators = max_value_params['estimators'],\n",
    "                            max_depth = max_value_params['depths'],\n",
    "                            colsample_bytree = max_value_params['colsample_bytree'],\n",
    "                            gamma = max_value_params['gamma'],\n",
    "                            learning_rate = max_value_params['learn'], random_state=1)\n",
    "\n",
    "# Fit the model\n",
    "xg_clf.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Predict\n",
    "y_pred_xgr = xg_clf.predict(X_test)\n",
    "\n",
    "# Extract accuracy\n",
    "xgr_acc_score = balanced_accuracy_score(y_pred_xgr, y_test)\n",
    "balanced_accuracy_score(y_pred_xgr, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3e0b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the confusion matrix for XGBoost\n",
    "cm = confusion_matrix(y_test, y_pred_xgr)\n",
    "\n",
    "#Display confusion matrix using ConfusinMatrixDisplay\n",
    "display_xgbr = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=xg_clf.classes_)\n",
    "display_xgbr.plot()\n",
    "\n",
    "class_xgr = classification_report(y_test, y_pred_xgr)\n",
    "# Create balanced classification report for XGBoost\n",
    "print(\"XGBoost Classification Report (Oversampled)\")\n",
    "print(classification_report(y_test, y_pred_xgr))\n",
    "print(\"-----------------------------------\")\n",
    "print(f'Accuracy Score: {xgr_acc_score}')\n",
    "print(\"-----------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b567ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the XGBoost important features\n",
    "xgb.plot_importance(xg_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50b35e3",
   "metadata": {},
   "source": [
    "## Results Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4abb4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-----------------Balanced Random Forest------------------\")\n",
    "print(f'Random Forest Without Oversampling Accuracy: {brf_acc_score:.3f}')\n",
    "print(class_brf)\n",
    "print(\" \")\n",
    "print(\"-----------------Balanced Random Forest (Oversampled) ------------------\")\n",
    "print(f'Random Forest With Oversampling Accuracy: {brfr_acc_score:.3f}')\n",
    "print(class_brfr)\n",
    "print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e8a3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"----------------Extreme Gradient Boost (XGBoost)-------------------\")\n",
    "print(f'XGBoost Without Oversampling Accuracy: {xg_acc_score:.3f}')\n",
    "print(class_xg)\n",
    "print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83c70ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"----------------Extreme Gradient Boost (Oversampled)-------------------\")\n",
    "print(f'XGBoost With Oversampling Accuracy: {xgr_acc_score:.3f}')\n",
    "print(class_xgr)\n",
    "print(\" \")\n",
    "print(\"-----------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c52284",
   "metadata": {},
   "source": [
    "### Results Comparison: Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9190b580",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-----------------Balanced Random Forest------------------\")\n",
    "#Display confusion matrix using ConfusionMatrixDisplay\n",
    "display_brf.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42029f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-----------------Balanced Random Forest (Oversampled)------------------\")\n",
    "#Display confusion matrix using ConfusionMatrixDisplay\n",
    "display_brfr.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72da4d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"----------------Extreme Gradient Boost (XGBoost)-------------------\")\n",
    "#Display confusion matrix using ConfusionMatrixDisplay\n",
    "display_xgb.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55286552",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"----------------Extreme Gradient Boost (Oversampled)-------------------\")\n",
    "#Display confusion matrix using ConfusionMatrixDisplay\n",
    "display_xgbr.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac0f8c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
