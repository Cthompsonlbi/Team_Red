{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96fcb1fb",
   "metadata": {},
   "source": [
    "# Warning Run Time\n",
    "### File has excessive run time over 2+ hours!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a02ce357",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54d8173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from config import db_password\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# stopwatch\n",
    "import time\n",
    "\n",
    "# ML\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier, EasyEnsembleClassifier\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bfec7c",
   "metadata": {},
   "source": [
    "## Connection to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce772f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create connection string to postgres DB\n",
    "# db_string =f'postgresql://postgres:{db_password}@127.0.0.1:5432/Project Insights on the Beach'\n",
    "# engine = create_engine(db_string)\n",
    "\n",
    "# read in the clean data from PGAdmin - SQL \n",
    "#vacay_df = pd.read_sql_query('''SELECT*FROM cleaned_up_cust_marketing_table;''',engine)\n",
    "\n",
    "# If not connected\n",
    "vacay_df = pd.read_csv(\"../cleaned_up_cust_marketing_table.csv\")\n",
    "\n",
    "vacay_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a3dc6c",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52083f1e",
   "metadata": {},
   "source": [
    "#### Remove target and unrelated columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c121c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns not needed\n",
    "features_df = vacay_df.copy()\n",
    "features_df = features_df.drop([\"prodtaken\",\"customerid\",\"designation\",\"numberofpersonvisiting\",\"numberofchildrenvisiting\"], axis=1)\n",
    "features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb52029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate our categorical variable list\n",
    "features_df_cat = features_df.dtypes[features_df.dtypes == \"object\"].index.tolist()\n",
    "\n",
    "# Check the number of unique values in each column\n",
    "features_df[features_df_cat].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3bd025",
   "metadata": {},
   "source": [
    "#### OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ca9fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a OneHotEncoder instance\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Fit and transform the OneHotEncoder using the categorical variable list\n",
    "encode_df = pd.DataFrame(enc.fit_transform(features_df[features_df_cat]))\n",
    "\n",
    "# Add the encoded variable names to the dataframe\n",
    "encode_df.columns = enc.get_feature_names(features_df_cat)\n",
    "encode_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b015999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge one-hot encoded features to features_df\n",
    "features_df = features_df.merge(encode_df,left_index=True, right_index=True)\n",
    "\n",
    "# Remove original unencoded columns\n",
    "features_df = features_df.drop(features_df_cat,1)\n",
    "features_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2b28d2",
   "metadata": {},
   "source": [
    "#### Scaling X, splitting test groups, and resampling with Naive Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75aed843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the features set.\n",
    "X = features_df.copy()\n",
    "\n",
    "# Define the target set.\n",
    "y = vacay_df[\"prodtaken\"]\n",
    "\n",
    "# Check the balance of our target values\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d211872b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data with StandardScaler()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the data\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# View first row\n",
    "X_scaled[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43c312d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, random_state=78)\n",
    "\n",
    "# Resample the training data with the RandomOversampler\n",
    "ros = RandomOverSampler(random_state=1)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b317053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the train vs test allocation\n",
    "print(Counter(y_train))\n",
    "print(Counter(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ee6c7d",
   "metadata": {},
   "source": [
    "## Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5e0cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Stratified K-Fold Cross Validation (5 & 10-Fold)\n",
    "n_folds = [5,10]\n",
    "\n",
    "estimators = [100, 250, 500, 750, 1000]\n",
    "accuracy_scores = []\n",
    "\n",
    "for fold in n_folds:\n",
    "    skf = StratifiedKFold(n_splits=fold)\n",
    "    for e in estimators:\n",
    "\n",
    "        # Instantiate random forest classifier and set results to 0 for each iteration\n",
    "        brclf = BalancedRandomForestClassifier(random_state=1, n_estimators=e)\n",
    "        results = 0\n",
    "\n",
    "        # split the data in train and validation sets\n",
    "        for train_index, test_index in skf.split(X_scaled, y):\n",
    "            X_t = X_scaled[train_index]\n",
    "            X_val = X_scaled[test_index]\n",
    "            y_t = y[train_index]\n",
    "            y_val = y[test_index]\n",
    "\n",
    "            # fit\n",
    "            brclf=brclf.fit(X_t, y_t)\n",
    "\n",
    "            # predict\n",
    "            y_pred_k = brclf.predict(X_val)\n",
    "\n",
    "            # extract accuracy score\n",
    "            results += balanced_accuracy_score(y_val, y_pred_k)\n",
    "\n",
    "        # add mean of total result to accuracy score list\n",
    "        accuracy_scores.append(results/fold)\n",
    "\n",
    "        # Print results\n",
    "        print(f'Acc Score with {fold} folds and {e} estimators: {accuracy_scores[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f49ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model with optimal estimators\n",
    "brclf = BalancedRandomForestClassifier(n_estimators=500, random_state=1)\n",
    "\n",
    "# fit\n",
    "brclf.fit(X_train, y_train)\n",
    "\n",
    "# predict\n",
    "y_pred = brclf.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "print(balanced_accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b424a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "#Display confusion matrix using ConfusinMatrixDisplay\n",
    "display = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=brclf.classes_)\n",
    "display.plot()\n",
    "\n",
    "#Save Image\n",
    "#plt.savefig(\"../Images/brf_cm.png\")\n",
    "plt.show()\n",
    "\n",
    "# Create balanced classification report for Random Forest\n",
    "print(\"Balanced Random Forest Classifier\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f210f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the features sorted in descending order by feature importance\n",
    "by_features = sorted(zip(brclf.feature_importances_, X.columns), reverse=True)\n",
    "for feature_rank in by_features:\n",
    "    print(f\"{feature_rank[1]}: ({feature_rank[0]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d1cb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chart important features in K-Fold Random Forest\n",
    "feat_importances = pd.Series(brclf.feature_importances_, index=X.columns)\n",
    "feat_importances.nlargest(20).plot(kind='barh',color=['blue', 'red', 'green', 'yellow', 'cyan']).invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f479de03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70697232",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebf1b9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971e4242",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f05c1f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41cb7f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33c7c35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
